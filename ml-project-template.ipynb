{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TITLE] General Data Science/ML Project Template\n",
    "\n",
    "- Author: Kevin Chuang [@k-chuang](https://github.com/k-chuang)\n",
    "- Date: 10/07/2018\n",
    "- Description: A jupyter notebook template for steps in solving a data science and/or machine learning problem.\n",
    "- Dataset: [Link to dataset source]()\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- **Introduction / Abstract**\n",
    "- **Load libraries & get data**\n",
    "    - Split data to training and test set\n",
    "        - stratified sampling based on certain feature(s) or label(s)\n",
    "- **Exploratory Data Analysis**\n",
    "    - Discover and visualize the training data to gain insights\n",
    "- **Data Preprocessing**\n",
    "    - Prepare data for ML algorithms\n",
    "    - Write pipelines using transformers to do automated feature engineering:\n",
    "        - Data scaling\n",
    "        - Impute missing data (or remove)\n",
    "        - Feature extraction\n",
    "            - Create new dimensions by combining existing ones\n",
    "        - Feature selection\n",
    "            - Choose subset of features from the existing features\n",
    "- **Model Selection & Training**\n",
    "    - Use K-Folds Cross-Validation to select top 2 to 5 most promising models\n",
    "        - Do not spend too much time tweaking hyperparameters\n",
    "    - Typical ML models include kNN, SVM, linear/logistic regression, ensemble methods (RF, XGB), neural networks, etc.\n",
    "    - [Optional] Save experimental models to pickle file.\n",
    "- **Model Tuning**\n",
    "    - `GridSearchCV`, `RandomSearchCV`, or `BayesSearchCV`\n",
    "        - `GridSearchCV`: brute force way to search for 'best' hyperparameters\n",
    "        - `BayesSearchCV`: smart way to use Bayesian inference to optimally search for best hyperparameters\n",
    "- **Model Evaluation**\n",
    "    - Final evaluation on hold out test set\n",
    "    - If regression, calculate 95% confidence interval range\n",
    "        - t score or z score to calculate confidence interval\n",
    "- **Solution Presentation and/or submission**\n",
    "    - What I learned, what worked & what did not, what assumptions were made, and what system's limitations are\n",
    "    - Create clear visualizations & easy-to-remember statements\n",
    "- **Deployment**\n",
    "    - Clean up and concatenate pipleines to single pipeline to do full data preparation plus final prediction\n",
    "    - Create programs to monitor & check system's live performance    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction / Abstract\n",
    "\n",
    "- Write a paragraph about the project/problem at hand\n",
    "    - Look at the big picture\n",
    "    - Frame the problem\n",
    "        - Business objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries & data\n",
    "\n",
    "- Load important libraries\n",
    "- Load (or acquire) associated data\n",
    "- Split data into training and test set\n",
    "    - Based on either feature importance or class imbalance, use *stratified sampling* to split data to keep porportion even for training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Kevin Chuang (https://www.github.com/k-chuang)' \n",
    "\n",
    "# Version check\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Metrics \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model Selection & Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space  import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Mathematical Functions\n",
    "import math\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "- Visualize training data using different kinds of plots\n",
    "- Plot dependent variables (features) against independent variable (target label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Writing pipelines to do automated feature engineering\n",
    "    - Imputing missing values (or removing values)\n",
    "    - Scaling data\n",
    "    - Transforming objects (strings, dates, etc.) to numerical vectors\n",
    "    - Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection & Training\n",
    "\n",
    "- Try different models and choose best 2-5 models\n",
    "    - Use K-Fold cross-validation to validate which models are the best\n",
    "- Typical ML models include kNN, SVM, linear/logistic regression, ensemble methods (RF, XGB), neural networks, etc.\n",
    "- [Optional] Save experimental models to pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "- Tune the top chosen model(s) and tune hyperparameters\n",
    "    - Ideally, use Bayes Optimization `BayesSearchCV` to optimally search for best hyperparameters for the model\n",
    "        - `BayesSearchCV` is from `skopt` or `scikit-optimize` library (There are many different Bayesian Optimization implementations) \n",
    "- Below are some common search spaces for ensemble algorithms (which tend to have a lot of hyperparameters), specifically:\n",
    "    - Random Forest (Variation of Bagging)\n",
    "    - xgboost (Gradient Boosting)\n",
    "    - lightgbm (Gradient Boosting)\n",
    "        - https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (Classificaton Example)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_search_space = {\n",
    "    'n_estimators': (100, 600),\n",
    "    'max_depth': (1, 50),  \n",
    "    'max_features': (1, n_features),\n",
    "    'min_samples_leaf': (1, 50),  # integer valued parameter\n",
    "    'min_samples_split': (2, 50),\n",
    "}\n",
    "\n",
    "rf_bayes_tuner = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(oob_score=True, random_state=1, n_jobs=2),\n",
    "    search_spaces=rf_search_space,\n",
    "    n_iter=20,\n",
    "    optimizer_kwargs={'base_estimator': 'RF'},\n",
    "    scoring='neg_log_loss',\n",
    "    n_jobs=5,\n",
    "    verbose=0,\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=1\n",
    "    ),\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "\n",
    "def status_print(result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(rf_bayes_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(rf_bayes_tuner.best_params_)\n",
    "    print('Model #{}\\nBest LogLoss: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(rf_bayes_tuner.best_score_, 6),\n",
    "        rf_bayes_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = rf_bayes_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name + \"_cv_results.csv\")\n",
    "\n",
    "    \n",
    "# Fit the model\n",
    "result = rf_bayes_tuner.fit(X_train.values, Y_train.values, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB (Classification Example)\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_search_space = { \n",
    "        # log-uniform: understand as search over p = exp(x) by varying x\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (0, 10),\n",
    "        'max_depth': (1, 100),\n",
    "        'max_delta_step': (0, 20),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': (0, 5),\n",
    "        'n_estimators': (50, 500),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "}\n",
    "\n",
    "xgb_bayes_tuner = BayesSearchCV(\n",
    "    estimator = xgb.XGBClassifier(\n",
    "        n_jobs = 3,\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        silent=1,\n",
    "        random_state=1\n",
    "    ),\n",
    "    search_spaces = xgb_search_space,    \n",
    "    scoring = 'neg_log_loss',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=1\n",
    "    ),\n",
    "    n_jobs = 6,\n",
    "    n_iter = 20,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "def status_print(result):\n",
    "    \"\"\"Status callback during bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(xgb_bayes_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(xgb_bayes_tuner.best_params_)\n",
    "    print('Model #{}\\nBest Log Loss: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(xgb_bayes_tuner.best_score_, 8),\n",
    "        xgb_bayes_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = xgb_bayes_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name + \"_cv_results.csv\")\n",
    "\n",
    "# Fit the model\n",
    "result = xgb_bayes_tuner.fit(X_train.values, Y_train.values, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB (Regression Example)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_search_space  = {\n",
    "    'max_depth': (3, 10),\n",
    "    'num_leaves': (6, 30),\n",
    "    'min_child_samples': (50, 200),\n",
    "    'subsample': (0.5, 1.0, 'uniform'),\n",
    "    'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "    'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "    'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    'n_estimators': (50, 500),\n",
    "    'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
    "    'learning_rate': (0.01, 0.2, 'uniform')\n",
    "}\n",
    "\n",
    "\n",
    "lgb_bayes_tuner = BayesSearchCV(\n",
    "    estimator = lgb.LGBMRegressor(\n",
    "        n_jobs = 3,\n",
    "        boosting_type=\"gbdt\",\n",
    "        objective = 'regression',\n",
    "        silent=1,\n",
    "        random_state=1\n",
    "    ),\n",
    "    search_spaces = lgb_search_space,    \n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 3,\n",
    "    n_jobs = 3,\n",
    "    n_iter = 20,   \n",
    "    verbose = 3,\n",
    "    refit = True,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "def status_print(result):\n",
    "    \"\"\"Status callback during bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(lgb_bayes_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(lgb_bayes_tuner.best_params_)\n",
    "    print('Model #{}\\nBest Log Loss: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(lgb_bayes_tuner.best_score_, 8),\n",
    "        lgb_bayes_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = lgb_bayes_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name + \"_cv_results.csv\")\n",
    "\n",
    "lgb_bayes_tuner.fit(housing_prepared, housing_labels, callback=status_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "- Final evaluation on the test set\n",
    "- Calculation of confidence intervals using t-score or z-scores to give a range of values and confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
